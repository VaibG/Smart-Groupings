{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Smart Donut Bot\n",
    "\n",
    "In this notebook, we create a smart group of pairings that will allow you to make donut groups that meet new people! The initial few cells are to be run once, and then you can run specific cells on a weekly basis to generate new matches. Try not to restart the algorithm midway through running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from airtable import airtable\n",
    "import fbchat\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = fbchat.Client('EMAIL', 'PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, we've imported a few libraries above that will allow us to do some quick data manipulation! The cell below us is quite important as it is the place you are able to manipulate the donut bot's constraints. It is recommended not to change these constraints after you have started running the algorithm (for the first few weeks), but if you need do end up changing these constraints, the places with **bold text** are the cells you need to re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "N = 3 #Number of people in each group, if there's is excess, it will create groups of N+1\n",
    "initial_weight = 1 #Starting weight for every member\n",
    "same_joined_semester = 0.5 #If they joined the same semester, they will be weighted less likely to be matched. Make it 0 if you don't want it to be a factor\n",
    "POPA = 0.01 #probability_of_paired_again \n",
    "table_name = \"Table 2\" #name of your airtable table in your Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, upload a roster file for your student organization. The file should follow this format with the column names exactly matching the table. All columns except 'Name' and 'Class' are optional. \n",
    "\n",
    "| Name | Class       | Expected Graduation | Never Match       |\n",
    "|:----:|-------------|||\n",
    "| XYZ  | Spring 2020 |      |             |\n",
    "| YSA  | Fall 2017   |      |             |\n",
    "| ADE  | Spring 2019 |      |             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = pd.read_csv('') #INPUT FILEPATH TO ROSTER HERE\n",
    "roster.head(5)\n",
    "n = roster['Name'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the roster, we are going to generate a dictionary of dictionaries and set their initial weights. This will be the the probability that one person gets matched to another person. If you want to add more inital weights, you can do so at the comment. These next two cells should only ever be run *once*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memberNames = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in n:\n",
    "    memberNames[name] = {}\n",
    "    year_joined = roster.loc[roster['Name'] == name, 'Class'].iloc[0]\n",
    "    for name2 in n:\n",
    "        if name != name2:\n",
    "            memberNames[name][name2] = initial_weight\n",
    "            year_joined_two = roster.loc[roster['Name'] == name2, 'Class'].iloc[0]\n",
    "            if year_joined == year_joined_two:\n",
    "                memberNames[name][name2] -= same_joined_semester\n",
    "            #other weightings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code that matches members based on their weightings. This is what should be run every time you want to generate new **matches** and continue till the end of the notebook.\n",
    "\n",
    "If you would like to change N (number of people in each group) copy and paste one of the blocks and change third to fourth, fifth etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weightings.csv')\n",
    "df = df.set_index(list(df.columns)[0])\n",
    "memberNames = df.to_dict()\n",
    "memberNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "n_copy = n\n",
    "while len(n) >= N:\n",
    "    group = np.array([])\n",
    "    first_rand = np.random.choice(n)\n",
    "    group = np.append(group, first_rand)\n",
    "    n = n[n != first_rand]\n",
    "    \n",
    "    probs = np.array([memberNames[first_rand][name] for name in n])\n",
    "    probs = probs / probs.sum()\n",
    "    second_rand = np.random.choice(n, 1, p=probs, replace=False)[0]\n",
    "    n = n[n != second_rand]\n",
    "    group = np.append(group,second_rand)\n",
    "\n",
    "    #copy block\n",
    "    probs = np.array([memberNames[first_rand][name] + memberNames[second_rand][name] for name in n])\n",
    "    probs = probs / probs.sum()\n",
    "    third_rand = np.random.choice(n, 1, p=probs, replace=False)\n",
    "    n = n[n != third_rand]\n",
    "    group = np.append(group,third_rand)\n",
    "    #end copy\n",
    "    \n",
    "    groups.append(group)\n",
    "\n",
    "for ind, remainder in enumerate(n):\n",
    "    groups[0] = np.append(groups[0], remainder)\n",
    "\n",
    "n = n_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change N, create Person_5, Person_6 etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_groups = pd.DataFrame(groups, columns=[\"Person_1\", \"Person_2\", \"Person_3\", \"Person_4\"])\n",
    "display_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block will send messenger messages from your facebook account, enter your Facebook email and password below. None of this will be saved so your information is secure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Messenger Messaging\n",
    "for index, row in display_groups.iterrows():\n",
    "    if index >=7:\n",
    "        messagList = []\n",
    "        user = client.searchForUsers(row['Person_1'])[0].uid\n",
    "        messagList.append(user)\n",
    "        time.sleep(4*random.random())\n",
    "        user2 = client.searchForUsers(row['Person_2'])[0].uid\n",
    "        messagList.append(user2)\n",
    "        time.sleep(4*random.random())\n",
    "        user3 = client.searchForUsers(row['Person_3'])[0].uid\n",
    "        messagList.append(user3)\n",
    "        time.sleep(4*random.random())\n",
    "        if row['Person_4'] is not None:\n",
    "            user4 = client.searchForUsers(row['Person_4'])[0].uid\n",
    "            messagList.append(user4)\n",
    "        client.createGroup(\"Hi, welcome to your first grouping!! Use this group to either virtually hangout, play a game and get to know each other. You don't have to use this group but it'd be cool for y'all to catch up and get to know each other if you don't already\", messagList)\n",
    "        time.sleep(7 + 6 * random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_groups['Group'] = display_groups.apply(lambda x: ', '.join(x[x.notnull()]), axis = 1)\n",
    "display_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code snippet links this notebook to your Airtable Base. For more information on how to do that contact Vaibhav Gattani at vaibg@berkeley.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_groups_filtered = display_groups[['Group']]\n",
    "records = display_groups_filtered.to_dict('records')\n",
    "at = airtable.Airtable('BASE ID', 'API KEY') #EDIT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all records\n",
    "for r in records:\n",
    "    at.create(table_name, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = airtable.Airtable('BASE ID', 'API KEY') #EDIT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weightings.csv')\n",
    "df = df.set_index(list(df.columns)[0])\n",
    "memberNames = df.to_dict()\n",
    "memberNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch all records\n",
    "our_table = at.get(table_name)\n",
    "filtered_table = [record['fields'] for record in our_table['records']]\n",
    "fetch_groups = pd.DataFrame(filtered_table)\n",
    "fetch_groups['createdTime'] = [record['createdTime'] for record in our_table['records']]\n",
    "fetch_groups = fetch_groups.sort_values(\"createdTime\", ascending=False)\n",
    "fetch_groups = fetch_groups.drop_duplicates(subset=[\"Group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update weights for each group\n",
    "groups = fetch_groups[['Group','Attended']].to_numpy()\n",
    "\n",
    "for name in n:\n",
    "    for name2 in n:\n",
    "        if name != name2:\n",
    "            if memberNames[name][name2] == POPA:\n",
    "                memberNames[name][name2] += POPA\n",
    "            elif memberNames[name][name2] == 2*POPA:\n",
    "                memberNames[name][name2] += POPA\n",
    "            elif memberNames[name][name2] == 3*POPA:\n",
    "                memberNames[name][name2] = 1\n",
    "    group = [x for x in groups if name in x[0]][0]\n",
    "    for name2 in group[0].split(', '):\n",
    "        if name != name2:\n",
    "            if group[1] is True:\n",
    "                memberNames[name][name2] = POPA\n",
    "            else:\n",
    "                memberNames[name][name2] = memberNames[name][name2]/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've updated our weights, we can delete all records in our Airtable Base and create new ones of the next week's pairings by running the matching algorithm again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all records\n",
    "our_table = at.get(table_name)\n",
    "for r in our_table['records']:\n",
    "    at.delete(table_name, r['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightings = pd.DataFrame(memberNames)\n",
    "weightings.to_csv('weightings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
